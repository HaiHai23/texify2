{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ASUS\\\\Documents\\\\GitHub\\\\texify'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded texify model to cpu with torch.float32 dtype\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from texify.inference import batch_inference\n",
    "from texify.model.model import load_model\n",
    "from texify.model.processor import load_processor\n",
    "from PIL import Image\n",
    "\n",
    "model = load_model()\n",
    "processor = load_processor()\n",
    "img = Image.open(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\test.jpg\") # Your image name here\n",
    "results = batch_inference([img], model, processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n\\\\begin{tabular}{l l}\\n\\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} \\\\begin{tabular}{l} ']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\\begin{tabular}{c c} \\hline \\multicolumn{2}{c}{UNDIUY(EN IIOAI)D(C & K$\\dot{\\gamma}$THI ICTION IOC SINH GIOI L$\\dot{\\gamma}$P 9}\\\\ \\hline P$\\dot{\\varepsilon}$chinn h$\\dot{\\alpha}$t & N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$m h$\\dot{\\alpha}$ 2024-2025 \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2024} \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "\\begin{tabular}{c c} \\hline \\multicolumn{2}{c}{UNDIUY(EN IIOAI)D(C & K$\\dot{\\gamma}$THI ICTION IOC SINH GIOI L$\\dot{\\gamma}$P 9}\\\\ \\hline P$\\dot{\\varepsilon}$chinn h$\\dot{\\alpha}$t & N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$m h$\\dot{\\alpha}$ 2024-2025 \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2024} \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(results[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\\begin{tabular}{c c} \\hline \\multicolumn{2}{c}{UNDIUY(EN IIOAI)D(C & K$\\dot{\\gamma}$THI ICTION IOC SINH GIOI L$\\dot{\\gamma}$P 9}\\\\ \\hline P$\\dot{\\varepsilon}$chinn h$\\dot{\\alpha}$t & N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$m h$\\dot{\\alpha}$ 2024-2025 \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2024} \\\\ \\hline \\multicolumn{2}{c}{N$\\dot{\\alpha}$t 100: An. N$\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2}{c}{B$\\dot{\\alpha}$t 100: $\\dot{\\alpha}$t 2024-2025} \\\\ \\hline \\multicolumn{2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. JSON files saved in: C:\\Users\\ASUS\\Downloads\\New folder\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the folder with PNG and TXT files\n",
    "input_folder = 'C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder'\n",
    "output_folder = 'C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Function to convert PNG file to JSON (metadata only)\n",
    "def png_to_json(file_path, output_folder):\n",
    "    with Image.open(file_path) as img:\n",
    "        img_data = {\n",
    "            \"filename\": os.path.basename(file_path),\n",
    "            \"size\": img.size,\n",
    "            \"mode\": img.mode,\n",
    "            \"format\": img.format,\n",
    "        }\n",
    "    json_path = os.path.join(output_folder, os.path.basename(file_path).replace('.png', '.json'))\n",
    "    with open(json_path, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(img_data, f)\n",
    "\n",
    "# Function to convert TXT file to JSON\n",
    "def txt_to_json(file_path, output_folder):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    json_data = {\n",
    "        \"filename\": os.path.basename(file_path),\n",
    "        \"content\": content\n",
    "    }\n",
    "    json_path = os.path.join(output_folder, os.path.basename(file_path).replace('.txt', '.json'))\n",
    "    with open(json_path, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(json_data, f)\n",
    "\n",
    "# Process each file in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    if filename.lower().endswith('.png'):\n",
    "        png_to_json(file_path, output_folder)\n",
    "    elif filename.lower().endswith('.txt'):\n",
    "        txt_to_json(file_path, output_folder)\n",
    "\n",
    "print(\"Conversion completed. JSON files saved in:\", output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, VisionEncoderDecoderModel, GenerationMixin, PretrainedConfig, PreTrainedModel, VisionEncoderDecoderConfig, AutoModelForCausalLM\n",
    "from transformers.models.donut.modeling_donut_swin import DonutSwinPatchEmbeddings, DonutSwinEmbeddings, DonutSwinModel, \\\n",
    "    DonutSwinEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion completed. JSON file saved as: C:\\Users\\ASUS\\Downloads\\New folder\\combined_data.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "# Path to the folder with PNG and TXT files\n",
    "input_folder = 'C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder'\n",
    "output_json_path = os.path.join(input_folder, 'combined_data.json')\n",
    "\n",
    "# Function to extract PNG file metadata\n",
    "def png_to_data(file_path):\n",
    "    with Image.open(file_path) as img:\n",
    "        img_data = {\n",
    "            \"filename\": os.path.basename(file_path),\n",
    "            \"size\": img.size,\n",
    "            \"mode\": img.mode,\n",
    "            \"format\": img.format,\n",
    "        }\n",
    "    return img_data\n",
    "\n",
    "# Function to extract TXT file content\n",
    "def txt_to_data(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "    return {\n",
    "        \"filename\": os.path.basename(file_path),\n",
    "        \"content\": content\n",
    "    }\n",
    "\n",
    "# Collect data for all files\n",
    "combined_data = {}\n",
    "\n",
    "# Process each file in the input folder\n",
    "for filename in os.listdir(input_folder):\n",
    "    file_path = os.path.join(input_folder, filename)\n",
    "    if filename.lower().endswith('.png'):\n",
    "        combined_data[filename] = png_to_data(file_path)\n",
    "    elif filename.lower().endswith('.txt'):\n",
    "        combined_data[filename] = txt_to_data(file_path)\n",
    "\n",
    "# Save combined data to a single JSON file\n",
    "with open(output_json_path, 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(combined_data, f, indent=4)\n",
    "\n",
    "print(\"Conversion completed. JSON file saved as:\", output_json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import os\n",
    "import sys\n",
    "os.chdir('C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder')\n",
    "\n",
    "files = os.listdir()\n",
    "imgs = [f for f in files if f.endswith('.png')]\n",
    "txts = [f for f in files if f.endswith('.txt')]\n",
    "\n",
    "def image_to_base64(image_path):\n",
    "    # Open the image file\n",
    "    with Image.open(image_path) as image:\n",
    "        # Create a BytesIO buffer to hold the image data\n",
    "        buffered = BytesIO()\n",
    "        # Save the image to the buffer in PNG format\n",
    "        image.save(buffered, format=\"PNG\")\n",
    "        # Get the base64 encoded string from the buffer\n",
    "        base64_string = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "    return base64_string\n",
    "\n",
    "def read_txt(file):\n",
    "    with open(file, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "out = [{'name':image_to_base64(img)} for img in imgs]\n",
    "for i in range(len(out)):\n",
    "    out[i]['equation'] = read_txt(txts[i])\n",
    "\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def list_of_dicts_to_jsonl(list_of_dicts, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for item in list_of_dicts:\n",
    "            # Convert the dictionary to a JSON string and write it to the file\n",
    "            json_line = json.dumps(item)\n",
    "            f.write(json_line + '\\n')\n",
    "\n",
    "def list_of_dicts_to_json(list_of_dicts, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        # Convert the list of dictionaries to JSON and write it to the file\n",
    "        json.dump(list_of_dicts, f, indent=4)  # 'indent=4' makes it more readable\n",
    "\n",
    "list_of_dicts_to_json(out, 'data.json')\n",
    "list_of_dicts_to_jsonl(out, 'data.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "from PIL import Image\n",
    "from transformers import AutoTokenizer, VisionEncoderDecoderModel, Trainer, TrainingArguments, AutoFeatureExtractor\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "import json\n",
    "\n",
    "# Step 1: Load and preprocess your JSON data\n",
    "# Load data from your JSON file\n",
    "#data = load_dataset(\"json\",data_files=\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder\\\\data.json\")\n",
    "    # Add more entries here\n",
    "with open(\"C:\\\\Users\\\\ASUS\\\\Downloads\\\\New folder\\\\data.json\", \"r\") as f:\n",
    "    data = json.load(f)  # Load JSON data as a list of dictionaries\n",
    "\n",
    "# Decode base64 image and convert to PIL\n",
    "def decode_image(image_base64):\n",
    "    decoded = base64.b64decode(image_base64)\n",
    "    return Image.open(io.BytesIO(decoded)).convert(\"RGB\")\n",
    "\n",
    "# Preprocess data to convert into a Dataset object\n",
    "def preprocess_data(data):\n",
    "    processed_data = {\"image\": [], \"text\": []}\n",
    "    for item in data:\n",
    "        if \"name\" not in item or \"equation\" not in item:\n",
    "            print(f\"Missing keys in item: {item}\")  # Debug print\n",
    "            continue  # Skip items that don't have the necessary keys\n",
    "        processed_data[\"image\"].append(decode_image(item[\"name\"]))\n",
    "        processed_data[\"text\"].append(item[\"equation\"])\n",
    "    return Dataset.from_dict(processed_data)\n",
    "\n",
    "# Create dataset\n",
    "dataset = preprocess_data(data)\n",
    "\n",
    "# Split dataset for training and validation\n",
    "train_test_split = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split[\"train\"]\n",
    "eval_dataset = train_test_split[\"test\"]\n",
    "\n",
    "# Step 2: Load model, tokenizer, and feature extractor\n",
    "model_name = \"vikp/texify\"  # Adjust with your model name if needed\n",
    "model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#feature_extractor = model.encoder. # Extractor for images\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Preprocess function for dataset\n",
    "def preprocess_function(examples):\n",
    "    max_length = 1000  # Set the desired maximum length for all sequences\n",
    "\n",
    "    # Preprocess images and resize to ensure consistent shape\n",
    "    pixel_values = feature_extractor(\n",
    "        images=examples[\"image\"], \n",
    "        return_tensors=\"pt\", \n",
    "    ).pixel_values\n",
    "\n",
    "    # Tokenize text without padding and truncation\n",
    "    tokenized_labels = [tokenizer(text)[\"input_ids\"] for text in examples[\"text\"]]\n",
    "    print(tokenized_labels)\n",
    "\n",
    "    # Manually pad or truncate each sequence to `max_length`\n",
    "    padded_labels = []\n",
    "    for label_seq in tokenized_labels:\n",
    "        # Truncate if longer than max_length\n",
    "        if len(label_seq) > max_length:\n",
    "            label_seq = label_seq[:max_length]\n",
    "        # Pad with the pad token ID if shorter than max_length\n",
    "        else:\n",
    "            label_seq = label_seq + [tokenizer.pad_token_id] * (max_length - len(label_seq))\n",
    "        \n",
    "        # Replace pad tokens with -100 for ignored positions in the loss calculation\n",
    "        label_seq = [token if token != tokenizer.pad_token_id else -100 for token in label_seq]\n",
    "        # print(label_seq)\n",
    "        padded_labels.append(label_seq)\n",
    "\n",
    "    # Convert to tensor\n",
    "    labels = torch.tensor(padded_labels)\n",
    "    # print(len(labels))\n",
    "\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}\n",
    "\n",
    "# Apply preprocessing\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=False)\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=False)\n",
    "\n",
    "# Step 3: Set training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./fine_tuned_texify\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # per_device_train_batch_size=2,\n",
    "    # per_device_eval_batch_size=2,\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_steps=500,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Step 4: Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")\n",
    "\n",
    "# Step 5: Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model, tokenizer, and feature extractor\n",
    "trainer.save_model(\"./fine_tuned_texify\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_texify\")\n",
    "feature_extractor.save_pretrained(\"./fine_tuned_texify\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
